JAR CREATION

in the spark-app/ directory run the command
`sbt assembly`
the jar will be generated in the target/ directory

LOAD JAR

aws s3 cp spark-app/target/scala-2.13/<jar_name>.jar s3://project-bucket-ale-pipita/<job_name>.jar

CLUSTER CREATION

aws emr create-cluster \
    --name "Big Data Cluster" \
    --release-label "emr-7.3.0" \
    --applications Name=Hadoop Name=Spark \
    --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large InstanceGroupType=CORE,InstanceCount=2,InstanceType=m4.large \
    --service-role EMR_DefaultRole \
    --ec2-attributes InstanceProfile=EMR_EC2_DefaultRole,KeyName=pipitaKeys \
    --region "us-east-1" \
    --log-uri s3://project-bucket-ale-pipita/emr-logs/

OPTIMIZED CLUSTER

aws emr create-cluster \
    --name "Big Data Cluster" \
    --release-label "emr-7.3.0" \
    --applications Name=Hadoop Name=Spark \
    --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large \
                      InstanceGroupType=CORE,InstanceCount=2,InstanceType=m4.large \
    --service-role EMR_DefaultRole \
    --ec2-attributes InstanceProfile=EMR_EC2_DefaultRole,KeyName=pipitaKeys \
    --region "us-east-1" \
    --log-uri s3://project-bucket-ale-pipita/emr-logs/ \
    --configurations '[ 
        { 
            "Classification": "spark", 
            "Properties": { 
                "spark.executor.instances": "3", 
                "spark.executor.cores": "4", 
                "spark.executor.memory": "6G", 
                "spark.driver.memory": "4G", 
                "spark.driver.cores": "2" 
            } 
        } 
    ]'

"4 cores per executor, 6gb of executor memory (75% of 8gb), 4gb of driver memory and 2 cores for driver"

DEPLOY

aws emr add-steps \
  --cluster-id j-1DJI50W73TH79 \
  --steps '[{
    "Type": "Spark",
    "Name": "ExampleJob",
    "ActionOnFailure": "CONTINUE",
    "Args": [
      "--deploy-mode", "cluster",
      "--class", "example.ExampleJob",
      "s3://project-bucket-ale-pipita/main_job.jar"
    ]
  }]'
